{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla GAN MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./MNIST_data/\", one_hot= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128 # noise size for generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set placeholder\n",
    "\n",
    "GAN is also kind of unsupervised learning. You don't need to set label data Y. But you set two placeholder X and Z. X is for real data set and Z is for inputting noise to generate fake data. Both X and Z are fed to discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables for Generator\n",
    "\n",
    "First variable(G_W1) and bias(G_b1) are variables for hidden layer and second variable(G_W2) and bias(G_b2) are for output. The shape of second variable is correspond to input image shape which enter to discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev= 0.01)) # (n_noise, n_hidden)\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden])) # (n_hidden,)\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev = 0.01)) # (n_hidden, n_input)\n",
    "G_b2 = tf.Variable(tf.zeros([n_input])) # (n_input,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables for Discriminator\n",
    "\n",
    "I just set the hidden layer of discriminator similar to generator. The output of discriminator is 0 or 1 in order to distinguish real or fake image. \n",
    "\n",
    "We must set the same variable in discriminator 1) which distinguish real image and 2) another discriminator which tell the generated image. Only if same variable is used when distinguising, Discriminator can figure out the real/fake image characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev= 0.01)) # (n_input, n_hidden)\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden])) # (n_hidden,)\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev = 0.01)) # (n_hidden, 1)\n",
    "D_b2 = tf.Variable(tf.zeros([1])) # (1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set generator & discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_z):\n",
    "    # input : noise_z (None, n_noise)\n",
    "    # output : output (None, 784)    \n",
    "    \n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1) # (None, n_hidden)\n",
    "    output = tf.nn.relu(tf.matmul(hidden, G_W2) + G_b2) # (None, 784)\n",
    "    return output\n",
    "\n",
    "def discriminator(inputs):\n",
    "    # input : inputs (None, 784)\n",
    "    # output : output (None, 1)\n",
    "    \n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1) # (None, n_hidden)\n",
    "    output = tf.sigmoid(tf.matmul(hidden, D_W2) + D_b2) # (None, 1)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set noise generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(batch_size, n_noise):\n",
    "    # output : random matrix (batch_size, n_noise)\n",
    "    \n",
    "    return np.random.normal(size = (batch_size, n_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator creates fake image by using random noise z. Discriminator get two inputs, first, fake images by generator and second, real images. Discriminator judge what is real and fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z) # (None, 784)\n",
    "D_gene = discriminator(G) # (None, 1)\n",
    "D_real = discriminator(X) # (None, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set loss\n",
    "\n",
    "+ 1. loss which discriminator judges that fake image generated by generator is `fake.`\n",
    "    - Example of counterfeit, this loss is relevent to **police.**\n",
    "+ 2. loss which discriminator judges that fake image generated by generator is `real.`\n",
    "    - Example of counterfeit, this loss is relevent to **counterfeiter**\n",
    "    \n",
    "For #1 loss of **police**, In order to train, D_real closes to '1'(discriminator judges that it's real) and D_gene closes to '0'(it's fake). SImply, `D_real` + `1- D_gene` makes loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For #2 loss of **counterfeiter**, In order to train, only D_gene should be closed to '1'. It means that discriminator judge that fake images as real or, Generator(counterfeiter) deceives Discriminator(police)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_G = tf.reduce_mean(tf.log(D_gene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object of GAN training is to maximize the loss_D & loss_G. But loss_D & loss_G are dependent. Accordingly, their increse or decrease relation is not proportional. Somtimes, they have inverse relation. Therefore they have `adversarial relation`.(So we call this network as adversarial network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**â€» Caution :** <br>\n",
    "Only discriminator variables are to be used only if you get loss_D. On the other hand, only generator variables must be used only if you get loss_G. By seperating this two loss, Getting loss_G doesn't change the discriminator variables and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_var_list = [D_W1, D_W2, D_b1, D_b2]\n",
    "G_var_list = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the GAN paper, loss must become maximum. But in most of deep learning framework(Tensorflow, Keras...), They supports only minimize optimizer. Therefore we set the **minus** to the `loss_G` and `loss_D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D, var_list = D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G, var_list = G_var_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 419.545454,
   "position": {
    "height": "40px",
    "left": "1011.82px",
    "right": "20px",
    "top": "120px",
    "width": "360px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
